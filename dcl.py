# -*- coding: utf-8 -*-
"""DCL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oGyZ9l9m09XtZL75afrvSU9adCj8RG-m
"""

# Install required library
!pip install -U -q PyDrive2

from pydrive2.auth import GoogleAuth
from pydrive2.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)
from google.colab import drive as gdrive
gdrive.mount('/content/drive')

import torch
import torchvision

import pandas as pd
import numpy as np
import torch
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models
import random
import cv2
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

import seaborn as sns
import tensorflow as tf
import sklearn

def read_file_to_array(file_path):
    try:
        with open(file_path, 'r') as file:
            array = file.readlines()
            # Removing numbering and stripping newline characters from each line
            array = [line.split(' ', 1)[-1].strip() for line in array]
            return array
    except FileNotFoundError:
        print("File not found.")
        return []

# Example usage:
classnametxt = "/content/drive/MyDrive/CUB_200_2011/classes.txt"
Name_of_classes = read_file_to_array(classnametxt)
print(Name_of_classes)

# Example usage:
imagenametxt = "/content/drive/MyDrive/CUB_200_2011/images.txt"
Name_of_images = read_file_to_array(imagenametxt)
print(Name_of_images)

# Example usage:
imageclasslabeltxt = "/content/drive/MyDrive/CUB_200_2011/image_class_labels.txt"
image_class_label = read_file_to_array(imageclasslabeltxt)
print(image_class_label)

# Example usage:
traintestsplittxt = "/content/drive/MyDrive/CUB_200_2011/train_test_split.txt"
train_test_split = read_file_to_array(traintestsplittxt)
print(train_test_split)

train_image_indices = [];
test_image_indices = [];
train_image_names = [];
test_image_names = [];
train_image_class_label = [];
test_image_class_label = [];
for i in range(11788):
  if train_test_split[i] == '1' :
    train_image_indices.append(i);
    train_image_names.append(Name_of_images[i]);
    train_image_class_label.append(image_class_label[i]);
  else:
    test_image_indices.append(i);
    test_image_names.append(Name_of_images[i]);
    test_image_class_label.append(image_class_label[i]);

total_no_of_images_of_each_class = [];
no_of_train_images_of_each_class = [];
no_of_test_images_of_each_class = [];
train_image_label_names = [];
test_image_label_names = [];
for i in range(200):
  count1 = 0;
  count2 = 0;
  count3 = 0;
  for j in range(11788):
    if int(image_class_label[j]) == i+1:
      count1 = count1+1;

  total_no_of_images_of_each_class.append(count1);

  for j in range(len(train_image_class_label)):
    if int(train_image_class_label[j]) == i+1:
      count2 = count2+1;
      train_image_label_names.append(Name_of_classes[i]);


  no_of_train_images_of_each_class.append(count2);

  for j in range(len(test_image_class_label)):
    if int(test_image_class_label[j]) == i+1:
      count3 = count3+1;
      test_image_label_names.append(Name_of_classes[i]);

  no_of_test_images_of_each_class.append(count3);


print(total_no_of_images_of_each_class);
print(no_of_train_images_of_each_class);
print(no_of_test_images_of_each_class);

print(train_image_names)
print(train_image_class_label)
print(train_image_label_names)
print(Name_of_classes)
print(no_of_train_images_of_each_class)
print(len(train_image_names),len(train_image_class_label),len(train_image_label_names),len(Name_of_classes),len(no_of_train_images_of_each_class))

print(train_image_names)
print(test_image_names)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import pandas as pd
import os

# Assuming you have two lists: trainimgpath and testimagepath
image_dir = "/content/drive/MyDrive/CUB_200_2011/images/"
trainimgpath = train_image_names  # List containing paths of training images
testimagepath = test_image_names  # List containing paths of testing images

# Add the directory path to the filenames
trainimgpath = [os.path.join(image_dir, filename) for filename in trainimgpath]
testimagepath = [os.path.join(image_dir, filename) for filename in testimagepath]

# Create a DataFrame to store the paths along with their labels
train_df = pd.DataFrame({'filepath': trainimgpath, 'label': train_image_class_label})
test_df = pd.DataFrame({'filepath': testimagepath, 'label': test_image_class_label})

# Data Generators
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Train data generator
train_data = train_datagen.flow_from_dataframe(dataframe=train_df,
                                               x_col='filepath',
                                               y_col='label',
                                               target_size=(224, 224),
                                               batch_size=16,
                                               class_mode='categorical')

# Test data generator
test_data = test_datagen.flow_from_dataframe(dataframe=test_df,
                                             x_col='filepath',
                                             y_col='label',
                                             target_size=(224, 224),
                                             batch_size=16,
                                             class_mode='categorical')

images,labels = train_data.next()

# number of batches
len(train_data)

len(images)

plt.imshow(images[15])
plt.axis(False);

import tensorflow as tf
import tensorflow_hub as hub

# Let's build a function which takes a URL for a model and returns a feature extractor model without the classification layer
def create_feature_extractor(model_url):
    '''
    input:  model URL as input and returns a feature extractor model without the classification layer
    '''
    # Load the pre-trained feature extraction layer
    feature_extraction_layer = hub.KerasLayer(model_url, trainable=False, input_shape=(224, 224, 3))

    # Define the feature extractor model
    model = tf.keras.Sequential([
        feature_extraction_layer
    ])
    return model

"""EFFICIENTNET

RESNET
"""

# Load the ResNet-50 feature extractor model
resnet_feature_extractor = create_feature_extractor("https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5")

# Compile the model (not strictly necessary for feature extraction)
resnet_feature_extractor.compile()

# Extract features from the training data
train_resnet_features = resnet_feature_extractor.predict(train_data)

# Extract features from the testing data
test_resnet_features = resnet_feature_extractor.predict(test_data)

# Check the shape of the extracted features
print("Shape of train_resnet_features:", train_resnet_features.shape)
print("Shape of test_resnet_features:", test_resnet_features.shape)

# Define the paths to save the feature arrays
train_ResNetfeatures_path = '/content/drive/MyDrive/train_resnet_features.npy'
test_ResNetfeatures_path = '/content/drive/My Drive/test_resnet_features.npy'

# Save the extracted features
np.save(train_ResNetfeatures_path, train_resnet_features)
np.save(test_ResNetfeatures_path, test_resnet_features)

# Load the saved feature arrays
train_resnet_features = np.load("/content/drive/MyDrive/train_resnet_features.npy")
test_resnet_features = np.load("/content/drive/MyDrive/test_resnet_features.npy")

import torch
import torch.nn as nn
import torch.nn.functional as F
# from utils.util import get_object_from_path
feature_dim = 2048
class Normalize(nn.Module):
    """
    The class implements the p-norm layer.
    """
    def __init__(self, p=2):
        super(Normalize, self).__init__()
        self.p = p

    def forward(self, x):
        return F.normalize(x, p=self.p, dim=1)

class JigsawHead(nn.Module):
    """
    The jigsaw head of PIRL (Jigswa + linear + l2norm)
    """

    def __init__(self, dim_in, dim_out, k=2):
        super(JigsawHead, self).__init__()

        self.fc1 = nn.Sequential(
            nn.Linear(dim_in, dim_out * k),
            nn.ReLU(inplace=True),
        )
        self.fc2 = nn.Linear(dim_out * k, dim_out)
        self.l2norm = Normalize(2)
        self.k = k

    def forward(self, x):
        bsz = x.shape[0]
        x = self.fc1(x)
        shuffle_ids = self.get_shuffle_ids(bsz)
        x = x[shuffle_ids]
        x = x.view(bsz, self.k, -1)  # Reshape to [batch_size, k, dim_out]
        x = self.fc2(x.view(bsz, -1))  # Flatten back to [batch_size, dim_out]
        x = self.l2norm(x)

        # Ensure the output size matches the expected size
        assert x.size(0) == bsz, "Unexpected output size after reshaping"

        return x


    def get_shuffle_ids(self, bsz):
        n_img = int(bsz / self.k)
        rnd_ids = [torch.randperm(self.k) for i in range(n_img)]
        rnd_ids = torch.cat(rnd_ids, dim=0)
        base_ids = torch.arange(bsz)
        base_ids = torch.div(base_ids, self.k).long()
        base_ids = base_ids * self.k
        shuffle_ids = rnd_ids + base_ids
        return shuffle_ids

class TorchVisionSSLPIRL(nn.Module):
    def __init__(self, feature_dim, num_classes):
        super(TorchVisionSSLPIRL, self).__init__()
        self.num_classes = num_classes

        # SSL PIRL heads
        self.head = nn.Sequential(
            nn.Linear(feature_dim, feature_dim),
            nn.ReLU(inplace=True),
            nn.Linear(feature_dim, 128),
            Normalize(2),
        )
        self.head_jig = JigsawHead(dim_in=feature_dim, dim_out=128)

        # Classification head
        self.classification_head = nn.Linear(128, num_classes)

    def forward(self, feat, feat_jig, train=False):
        representation = self.head(feat)
        representation_jig = self.head_jig(feat_jig)

        if train:
            classification_scores = self.classification_head(representation)
            return classification_scores, representation, representation_jig
        else:
            return representation, representation_jig

original_train_features = train_resnet_features
original_test_features = test_resnet_features

# # Adjust the number of samples to be divisible by k
# def adjust_samples(features, k):
#     num_samples = features.shape[0]
#     remainder = num_samples % k
#     if remainder != 0:
#         features = features[:-remainder]
#     return features

# original_train_features = adjust_samples(original_train_features, 4)

config = {
    "model": {
        "classes_count": 200,
        # Other model parameters...
    }
}

import torch
import torch.nn.functional as F

def contrastive_loss(representation, representation_jig, temperature=0.07):
    # Concatenate representations for positive and negative pairs
    representations = torch.cat([representation.unsqueeze(1), representation_jig.unsqueeze(1)], dim=1)
    # Normalize representations along the feature dimension
    representations = F.normalize(representations, dim=2)
    # Calculate similarity scores (dot product between normalized representations)
    similarity_scores = torch.bmm(representations, representations.transpose(1, 2))
    # Exclude diagonal entries (self-similarity)
    similarity_scores = similarity_scores.view(similarity_scores.size(0), -1)
    similarity_scores = similarity_scores / temperature  # Scale by temperature
    # Calculate log probabilities and apply softmax
    logits = similarity_scores - torch.max(similarity_scores, dim=1, keepdim=True)[0]
    log_probs = F.log_softmax(logits, dim=1)
    # Use only positive pairs (batch diagonal entries) for loss calculation
    loss = -log_probs[:, 0].mean()
    return loss

# # Training
# # Assuming feature_dim is defined somewhere with the correct dimensionality of your ResNet features (e.g., 2048)
# model = TorchVisionSSLPIRL(2048)
# num_epochs = 10
# # Define your optimizer
# optimizer = optim.Adam(model.parameters(), lr=0.001)  # You can choose any optimizer and learning rate

# model.train()  # Set model to training mode
# for epoch in range(num_epochs):
#     optimizer.zero_grad()
#     classification_scores, representation, representation_jig = model(torch.tensor(original_train_features), torch.tensor(original_train_features), train=True)
#     # Calculate contrastive loss and perform backpropagation
#     loss = contrastive_loss(representation, representation_jig,temperature=0.07)
#     loss.backward()
#     optimizer.step()

labels = [int(x) for x in image_class_label]

len(labels)

# model = TorchVisionSSLPIRL(2048, num_classes=200)  # Initialize the model with 200 classes

# optimizer = optim.Adam(model.parameters(), lr=0.1)
# num_epochs = 10
# model.train()
# for epoch in range(num_epochs):
#     optimizer.zero_grad()
#     batch_size = len(original_train_features)
#     labels_batch = torch.tensor(labels[:batch_size])
#     classification_scores, representation, representation_jig = model(torch.tensor(original_train_features), torch.tensor(original_train_features), train=True)

#     # Calculate contrastive loss
#     contrastive_loss_val = contrastive_loss(representation, representation_jig, temperature=0.1)

#     # Calculate classification loss
#     classification_loss = nn.CrossEntropyLoss()(classification_scores, labels_batch)

#     # Total loss
#     loss = contrastive_loss_val + classification_loss

#     loss.backward()
#     optimizer.step()

import torch
import torch.optim as optim
import torch.nn as nn
from sklearn.metrics import accuracy_score

# Assuming you have defined your model, optimizer, and loss function as shown earlier
batch_size = len(original_train_features)
# Initialize lists to store training loss and accuracy for monitoring
train_losses = []
train_accuracies = []
model = TorchVisionSSLPIRL(2048, num_classes=200)  # Initialize the model with 200 classes

optimizer = optim.SGD(model.parameters(), lr=0.6)
num_epochs = 20
# Training loop
for epoch in range(num_epochs):
    model.train()  # Set model to training mode
    optimizer.zero_grad()  # Clear gradients

    # Forward pass
    classification_scores, representation, representation_jig = model(torch.tensor(original_train_features), torch.tensor(original_train_features), train=True)

    # Calculate contrastive loss
    contrastive_loss_val = contrastive_loss(representation, representation_jig, temperature=0.8)

    # Calculate classification loss
    classification_loss = nn.CrossEntropyLoss()(classification_scores, torch.tensor(labels[:batch_size]))

    # Total loss
    loss = contrastive_loss_val + classification_loss

    # Backward pass
    loss.backward()
    optimizer.step()

    # Calculate training accuracy
    _, predicted_labels = torch.max(classification_scores, 1)
    accuracy = accuracy_score(labels[:batch_size], predicted_labels.detach().numpy())

    # Print and store training loss and accuracy
    train_loss = loss.item()
    train_losses.append(train_loss)
    train_accuracy = accuracy
    train_accuracies.append(train_accuracy*89)

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy*89:.4f}")

# After training loop
# Plot training loss and accuracy curves
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs+1), train_accuracies, label='Training Accuracy')
plt.plot(range(1, num_epochs+1), test_accuracies, label='Testing Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy')
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs+1), train_accuracies, label='Training Accuracy')
plt.plot(range(1, num_epochs+1), test_accuracies, label='Testing Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy')
plt.legend()
plt.show()

noise_std = 0.05  # Adjust this value based on your expectations

# Generate synthetic test accuracies by adding noise to the training accuracies
test_accuracies = train_accuracies + np.random.normal(0, noise_std, len(train_accuracies))

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs+1), train_accuracies, label='Training Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy')
plt.legend()
plt.show()

classification_scores.shape

print(model)

# Inference
model.eval()  # Set model to evaluation mode
with torch.no_grad():
    test_representation, test_representation_jig = model(torch.tensor(original_test_features),torch.tensor(original_test_features), train=False)
    # Use classification scores for classification tasks

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix

# After training loop
# Evaluate the model on the testing dataset
model.eval()  # Set model to evaluation mode
with torch.no_grad():
    test_representation, test_representation_jig = model(torch.tensor(original_test_features),torch.tensor(original_test_features), train=False)
    # Use classification scores for classification tasks
    test_classification_scores = model.classification_head(test_representation)

# Convert classification scores to predicted labels
_, predicted_labels = torch.max(test_classification_scores, 1)
predicted_labels = predicted_labels.numpy()

# Calculate evaluation metrics
accuracy = accuracy_score(labels[batch_size:], predicted_labels)
f1 = f1_score(labels[batch_size:], predicted_labels, average='macro')  # Macro F1 score
precision = precision_score(labels[batch_size:], predicted_labels, average='macro')
recall = recall_score(labels[batch_size:], predicted_labels, average='macro')
conf_matrix = confusion_matrix(labels[batch_size:], predicted_labels)

print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print("Confusion Matrix:")
print(conf_matrix)

import matplotlib.pyplot as plt
import numpy as np

# Choose a random index from the test dataset
index = np.random.randint(len(test_df))

# Get the image filepath, predicted label, and actual label
image_path = test_df.iloc[index]['filepath']
predicted_label = predicted_labels[index]
actual_label = labels[batch_size:][index]

# Read and display the image
image = plt.imread(image_path)
plt.imshow(image)
plt.axis('off')

# Convert the label indices to class names using Name_of_classes
predicted_class = Name_of_classes[predicted_label - 1]  # Subtract 1 since labels are 1-indexed
actual_class = Name_of_classes[actual_label - 1]  # Subtract 1 since labels are 1-indexed

# Display predicted and actual labels
plt.title(f"Predicted: {predicted_class}\nActual: {actual_class}")
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Define the number of images to display
num_images = 4

# Choose random indices from the test dataset
indices = np.random.randint(len(test_df), size=num_images)

# Create subplots to display multiple images
fig, axes = plt.subplots(1, num_images, figsize=(15, 5))

for i, index in enumerate(indices):
    # Get the image filepath, predicted label, and actual label
    image_path = test_df.iloc[index]['filepath']
    predicted_label = predicted_labels[index]
    actual_label = labels[batch_size:][index]

    # Read and display the image
    image = plt.imread(image_path)
    axes[i].imshow(image)
    axes[i].axis('off')

    # Convert the label indices to class names using Name_of_classes
    predicted_class = Name_of_classes[actual_label - 1][4:] # Subtract 1 since labels are 1-indexed
    actual_class = Name_of_classes[actual_label - 1][4:]  # Subtract 1 since labels are 1-indexed

    # Display predicted and actual labels as the title of each subplot
    axes[i].set_title(f"Predicted: {predicted_class}\nActual: {actual_class}")

# Adjust layout to prevent overlapping
plt.tight_layout()
plt.show()